{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv(\"/Users/deontaepharr/Desktop/data/breastcancer.csv\")\n",
    "\n",
    "X = heart_data.drop(\"class\", axis=1)\n",
    "y = heart_data[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 468 samples, validate on 231 samples\n",
      "Epoch 1/200\n",
      "468/468 [==============================] - 0s 904us/step - loss: 4.4804 - acc: 0.0000e+00 - val_loss: 4.0723 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 4.0866 - acc: 0.0000e+00 - val_loss: 3.8525 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.9563 - acc: 0.0000e+00 - val_loss: 3.7876 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.9094 - acc: 0.0000e+00 - val_loss: 3.7561 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "468/468 [==============================] - 0s 160us/step - loss: 3.8840 - acc: 0.0000e+00 - val_loss: 3.7365 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8675 - acc: 0.0000e+00 - val_loss: 3.7232 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8560 - acc: 0.0000e+00 - val_loss: 3.7136 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8474 - acc: 0.0000e+00 - val_loss: 3.7064 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8409 - acc: 0.0000e+00 - val_loss: 3.7008 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "468/468 [==============================] - 0s 154us/step - loss: 3.8359 - acc: 0.0000e+00 - val_loss: 3.6964 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8319 - acc: 0.0000e+00 - val_loss: 3.6929 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8287 - acc: 0.0000e+00 - val_loss: 3.6900 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8260 - acc: 0.0000e+00 - val_loss: 3.6876 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8238 - acc: 0.0000e+00 - val_loss: 3.6856 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "468/468 [==============================] - 0s 158us/step - loss: 3.8219 - acc: 0.0000e+00 - val_loss: 3.6839 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8202 - acc: 0.0000e+00 - val_loss: 3.6824 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8188 - acc: 0.0000e+00 - val_loss: 3.6811 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8176 - acc: 0.0000e+00 - val_loss: 3.6800 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8165 - acc: 0.0000e+00 - val_loss: 3.6789 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8155 - acc: 0.0000e+00 - val_loss: 3.6781 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8146 - acc: 0.0000e+00 - val_loss: 3.6772 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "468/468 [==============================] - 0s 173us/step - loss: 3.8138 - acc: 0.0000e+00 - val_loss: 3.6765 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8132 - acc: 0.0000e+00 - val_loss: 3.6759 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "468/468 [==============================] - 0s 173us/step - loss: 3.8125 - acc: 0.0000e+00 - val_loss: 3.6753 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8120 - acc: 0.0000e+00 - val_loss: 3.6748 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "468/468 [==============================] - 0s 173us/step - loss: 3.8114 - acc: 0.0000e+00 - val_loss: 3.6743 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8110 - acc: 0.0000e+00 - val_loss: 3.6738 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "468/468 [==============================] - 0s 168us/step - loss: 3.8105 - acc: 0.0000e+00 - val_loss: 3.6734 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8101 - acc: 0.0000e+00 - val_loss: 3.6731 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8098 - acc: 0.0000e+00 - val_loss: 3.6727 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8094 - acc: 0.0000e+00 - val_loss: 3.6724 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "468/468 [==============================] - 0s 169us/step - loss: 3.8091 - acc: 0.0000e+00 - val_loss: 3.6721 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8088 - acc: 0.0000e+00 - val_loss: 3.6718 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8086 - acc: 0.0000e+00 - val_loss: 3.6716 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8083 - acc: 0.0000e+00 - val_loss: 3.6713 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8081 - acc: 0.0000e+00 - val_loss: 3.6711 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8079 - acc: 0.0000e+00 - val_loss: 3.6709 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8077 - acc: 0.0000e+00 - val_loss: 3.6707 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8075 - acc: 0.0000e+00 - val_loss: 3.6705 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8073 - acc: 0.0000e+00 - val_loss: 3.6704 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8071 - acc: 0.0000e+00 - val_loss: 3.6702 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8070 - acc: 0.0000e+00 - val_loss: 3.6701 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8068 - acc: 0.0000e+00 - val_loss: 3.6699 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8067 - acc: 0.0000e+00 - val_loss: 3.6698 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8065 - acc: 0.0000e+00 - val_loss: 3.6697 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "468/468 [==============================] - 0s 160us/step - loss: 3.8064 - acc: 0.0000e+00 - val_loss: 3.6695 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8063 - acc: 0.0000e+00 - val_loss: 3.6694 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8062 - acc: 0.0000e+00 - val_loss: 3.6693 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "468/468 [==============================] - 0s 174us/step - loss: 3.8061 - acc: 0.0000e+00 - val_loss: 3.6692 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8060 - acc: 0.0000e+00 - val_loss: 3.6691 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8059 - acc: 0.0000e+00 - val_loss: 3.6690 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8058 - acc: 0.0000e+00 - val_loss: 3.6689 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "468/468 [==============================] - 0s 193us/step - loss: 3.8057 - acc: 0.0000e+00 - val_loss: 3.6689 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      "468/468 [==============================] - 0s 180us/step - loss: 3.8056 - acc: 0.0000e+00 - val_loss: 3.6688 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "468/468 [==============================] - 0s 174us/step - loss: 3.8055 - acc: 0.0000e+00 - val_loss: 3.6687 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8055 - acc: 0.0000e+00 - val_loss: 3.6686 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8054 - acc: 0.0000e+00 - val_loss: 3.6686 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8053 - acc: 0.0000e+00 - val_loss: 3.6685 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8053 - acc: 0.0000e+00 - val_loss: 3.6684 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8052 - acc: 0.0000e+00 - val_loss: 3.6684 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8051 - acc: 0.0000e+00 - val_loss: 3.6683 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "468/468 [==============================] - 0s 174us/step - loss: 3.8051 - acc: 0.0000e+00 - val_loss: 3.6683 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "468/468 [==============================] - 0s 178us/step - loss: 3.8050 - acc: 0.0000e+00 - val_loss: 3.6682 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8050 - acc: 0.0000e+00 - val_loss: 3.6682 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8049 - acc: 0.0000e+00 - val_loss: 3.6681 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8049 - acc: 0.0000e+00 - val_loss: 3.6681 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "468/468 [==============================] - 0s 155us/step - loss: 3.8048 - acc: 0.0000e+00 - val_loss: 3.6680 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8048 - acc: 0.0000e+00 - val_loss: 3.6680 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8047 - acc: 0.0000e+00 - val_loss: 3.6679 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8047 - acc: 0.0000e+00 - val_loss: 3.6679 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8047 - acc: 0.0000e+00 - val_loss: 3.6679 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8046 - acc: 0.0000e+00 - val_loss: 3.6678 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8046 - acc: 0.0000e+00 - val_loss: 3.6678 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8045 - acc: 0.0000e+00 - val_loss: 3.6678 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8045 - acc: 0.0000e+00 - val_loss: 3.6677 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8045 - acc: 0.0000e+00 - val_loss: 3.6677 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8045 - acc: 0.0000e+00 - val_loss: 3.6677 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8044 - acc: 0.0000e+00 - val_loss: 3.6676 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "468/468 [==============================] - 0s 155us/step - loss: 3.8044 - acc: 0.0000e+00 - val_loss: 3.6676 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "468/468 [==============================] - 0s 155us/step - loss: 3.8044 - acc: 0.0000e+00 - val_loss: 3.6676 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "468/468 [==============================] - 0s 150us/step - loss: 3.8043 - acc: 0.0000e+00 - val_loss: 3.6676 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8043 - acc: 0.0000e+00 - val_loss: 3.6675 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "468/468 [==============================] - 0s 158us/step - loss: 3.8043 - acc: 0.0000e+00 - val_loss: 3.6675 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8043 - acc: 0.0000e+00 - val_loss: 3.6675 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8042 - acc: 0.0000e+00 - val_loss: 3.6675 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8042 - acc: 0.0000e+00 - val_loss: 3.6674 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8042 - acc: 0.0000e+00 - val_loss: 3.6674 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8042 - acc: 0.0000e+00 - val_loss: 3.6674 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "468/468 [==============================] - 0s 149us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6674 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "468/468 [==============================] - 0s 151us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "468/468 [==============================] - 0s 151us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "468/468 [==============================] - 0s 151us/step - loss: 3.8041 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "468/468 [==============================] - 0s 154us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6673 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "468/468 [==============================] - 0s 149us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "468/468 [==============================] - 0s 151us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "468/468 [==============================] - 0s 167us/step - loss: 3.8040 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "468/468 [==============================] - 0s 174us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6672 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "468/468 [==============================] - 0s 167us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      "468/468 [==============================] - 0s 169us/step - loss: 3.8039 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "468/468 [==============================] - 0s 167us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6671 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "468/468 [==============================] - 0s 160us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8038 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "468/468 [==============================] - 0s 168us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "468/468 [==============================] - 0s 168us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6670 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      "468/468 [==============================] - 0s 166us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "468/468 [==============================] - 0s 169us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "468/468 [==============================] - 0s 173us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8037 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "468/468 [==============================] - 0s 160us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6669 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      "468/468 [==============================] - 0s 179us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      "468/468 [==============================] - 0s 176us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      "468/468 [==============================] - 0s 168us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      "468/468 [==============================] - 0s 171us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "468/468 [==============================] - 0s 176us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      "468/468 [==============================] - 0s 149us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      "468/468 [==============================] - 0s 149us/step - loss: 3.8036 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      "468/468 [==============================] - 0s 154us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      "468/468 [==============================] - 0s 155us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "468/468 [==============================] - 0s 158us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "468/468 [==============================] - 0s 167us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      "468/468 [==============================] - 0s 152us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      "468/468 [==============================] - 0s 156us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      "468/468 [==============================] - 0s 153us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      "468/468 [==============================] - 0s 154us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      "468/468 [==============================] - 0s 150us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      "468/468 [==============================] - 0s 148us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "468/468 [==============================] - 0s 157us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6668 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      "468/468 [==============================] - 0s 160us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      "468/468 [==============================] - 0s 159us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      "468/468 [==============================] - 0s 163us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      "468/468 [==============================] - 0s 177us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      "468/468 [==============================] - 0s 174us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      "468/468 [==============================] - 0s 172us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      "468/468 [==============================] - 0s 170us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      "468/468 [==============================] - 0s 164us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      "468/468 [==============================] - 0s 178us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      "468/468 [==============================] - 0s 162us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      "468/468 [==============================] - 0s 165us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      "468/468 [==============================] - 0s 161us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      "468/468 [==============================] - 0s 169us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      "468/468 [==============================] - 0s 167us/step - loss: 3.8035 - acc: 0.0000e+00 - val_loss: 3.6667 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=len(X.columns), activation='sigmoid'))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "results = model.fit(X_train, y_train, validation_data=(X_test, y_test), validation_split=0.33, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "history = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x115a7dba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Breast Cancer (Neural Network) Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
