{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from os import path\n",
    "\n",
    "import sys\n",
    "import fnmatch\n",
    "\n",
    "import Augmentor\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing - Organization and Augmenting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strain_directories(base_directory, strain_ids):\n",
    "    for strain in strain_ids:\n",
    "        try:\n",
    "            strain_path = os.path.join(base_directory, str(strain))\n",
    "            os.mkdir(strain_path)\n",
    "            print(\"Directory Created:\", strain_path)\n",
    "        except FileExistsError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images(base_directory, strain_ids):\n",
    "    for strain in strain_ids:\n",
    "        for file in os.listdir(base_directory):\n",
    "            strain_img = \"PIL-{}_*.jpg\".format(int(strain))\n",
    "            if fnmatch.fnmatch(file, strain_img):\n",
    "                image_path = os.path.join(base_directory,file)\n",
    "                mv_dir = os.path.join(base_directory,str(strain))\n",
    "                mv_path = os.path.join(mv_dir, file)\n",
    "                if os.path.exists(image_path):\n",
    "                    os.rename(image_path,mv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Up: Deletes Empty Directories\n",
    "def delete_empty_directories(base_directory):\n",
    "    directories = [x[0] for x in os.walk(base_directory)]\n",
    "    for directory in directories:\n",
    "        try:\n",
    "            os.rmdir(directory)\n",
    "        except OSError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizes the Images into their respective directories\n",
    "def organize_images(base_directory, dataset):\n",
    "    strain_ids = dataset[\"strain\"]\n",
    "    create_strain_directories(base_directory, strain_ids)\n",
    "    move_images(base_directory, strain_ids)\n",
    "    delete_empty_directories(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all the strain directories\n",
    "def get_strain_directories(base_directory):\n",
    "    strain_dirs = []\n",
    "    for root, dirs, files in os.walk(base_directory, topdown=False):\n",
    "        for name in dirs:\n",
    "            dir_path = os.path.join(base_directory, name)\n",
    "            if os.path.isdir(dir_path):\n",
    "                strain_dirs.append(dir_path)\n",
    "    return strain_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the path is a parent to ensure we're saving the augmented images in their correct directory\n",
    "def path_is_parent(parent_path, child_path):\n",
    "    parent_path = os.path.abspath(parent_path)\n",
    "    child_path = os.path.abspath(child_path)\n",
    "\n",
    "    return os.path.commonpath([parent_path]) == os.path.commonpath([parent_path, child_path])\n",
    "\n",
    "# Converts to grayscale\n",
    "def to_grayscale(strain_directory, output_dir):\n",
    "    try:\n",
    "        if not path_is_parent(strain_directory, output_dir):\n",
    "            print(\"Not the correct subdirectory\")\n",
    "            return\n",
    "\n",
    "        dirs = os.listdir( strain_directory )\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        for item in dirs:\n",
    "            if \".jpg\" in item:\n",
    "                img_file = os.path.join(strain_directory,item)\n",
    "                if os.path.isfile(img_file):\n",
    "                    file_name, extension = os.path.splitext(img_file)\n",
    "                    file_name = file_name + \"_gray.jpg\"\n",
    "                    new_file_location = join(output_dir,item)\n",
    "\n",
    "                    img = Image.open(img_file)        \n",
    "                    img_gray = img.convert('L')\n",
    "                    img_gray.save(file_name)\n",
    "\n",
    "                    os.rename(file_name, new_file_location) # moves file to new location\n",
    "    except Exception as e:\n",
    "        print(\"Issue with directory in to_grayscale() method:\", strain_directory)\n",
    "        print(e)\n",
    "        \n",
    "# Resizes Images\n",
    "def resize(strain_directory, output_dir):\n",
    "    try:\n",
    "        if not path_is_parent(strain_directory, output_dir):\n",
    "            print(\"Not the correct subdirectory\")\n",
    "            return\n",
    "\n",
    "        dirs = os.listdir( strain_directory )\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        for item in dirs:\n",
    "            if \".jpg\" in item:\n",
    "                img_file = os.path.join(strain_directory,item)\n",
    "                if os.path.isfile(img_file):\n",
    "                    file_name, extension = os.path.splitext(img_file)\n",
    "                    file_name = file_name + \"_resized.jpg\"\n",
    "                    new_file_location = join(output_dir,item)\n",
    "\n",
    "                    img = Image.open(img_file)\n",
    "                    file_name, extension = os.path.splitext(img_file)\n",
    "                    imResize = img.resize((28,28), Image.ANTIALIAS)\n",
    "                    imResize.save(file_name, 'JPEG', quality=90)\n",
    "\n",
    "                    os.rename(file_name, new_file_location) # moves file to new location\n",
    "    except Exception as e:\n",
    "        print(\"Issue with directory in resize() method:\", strain_directory)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augments the images\n",
    "def augment_strain_images(strain_dir, sample_size=20):\n",
    "    try:\n",
    "        p = Augmentor.Pipeline(strain_dir)\n",
    "        p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "        p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n",
    "        p.flip_left_right(probability=0.5)\n",
    "        p.flip_top_bottom(probability=0.5)\n",
    "        p.resize(probability=1.0, width=28, height=28)\n",
    "        p.sample(sample_size, multi_threaded=False)\n",
    "    except Exception as e:\n",
    "        print(\"Issue with directory in augment_strain_images() method:\", strain_dir)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes the entire images dataset\n",
    "def process_images(strain_directories, gray_strain_directories, output_strain_directories):\n",
    "    \n",
    "    # Converts original images to grayscale\n",
    "    for i in tqdm(range(len(strain_directories))):\n",
    "        to_grayscale(strain_directories[i], gray_strain_directories[i])\n",
    "    \n",
    "    # Augments the gray images\n",
    "    for image_dir in (gray_strain_directories):\n",
    "        augment_strain_images(image_dir)\n",
    "    \n",
    "    # (Just for completeness) Resizes the original grayscale images without augmentations\n",
    "    for i in tqdm(range(len(output_strain_directories))):\n",
    "        resize(gray_strain_directories[i], output_strain_directories[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path(path):\n",
    "    allparts = []\n",
    "    while True:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create excel sheet with strain id , image location pairs\n",
    "def get_strain_images_as_df(strain_directories):\n",
    "    strains = []\n",
    "    try: \n",
    "        for directory in strain_directories:        \n",
    "            strain_id = split_path(directory)[-3]\n",
    "\n",
    "            for item in os.listdir( directory ):\n",
    "                if \".jpg\" in item:\n",
    "                    image_path = os.path.join(directory,item)\n",
    "                    if os.path.exists(image_path):\n",
    "                        strain_dict = {\"strain\": strain_id, \"strain_image\":image_path}\n",
    "                        strains.append(strain_dict)\n",
    "                    else:\n",
    "                        print(\"Doesn't exist:\", image_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return pd.DataFrame(strains)\n",
    "\n",
    "def save_to_excel(excel_file, sheet_name, df):\n",
    "    book = load_workbook(excel_file)\n",
    "    writer = pd.ExcelWriter(excel_file)\n",
    "    writer.book  = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    df.to_excel(writer, sheet_name, index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joins datasets\n",
    "def merge_datasets(df_1, df_2):\n",
    "    info = []\n",
    "    for strain, row in df_1.iterrows():\n",
    "        try:\n",
    "            if '0' in strain[0]:\n",
    "                strain_id = pd.Series(strain, index=[\"strain_id\"])\n",
    "                info.append(df_2.loc[strain].append(row).append(strain_id))\n",
    "            else:\n",
    "                strain_id = pd.Series(strain, index=[\"strain_id\"])\n",
    "                info.append(df_2.loc[int(strain)].append(row).append(strain_id))\n",
    "        except Exception as e:\n",
    "            print(\"error with strain\", strain, \":\", e)\n",
    "\n",
    "    return pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"Enter path location for directory where the images are stored\"\n",
    "bacteria_workbook = \"Enter path location for excel file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_excel(bacteria_workbook, dtype=object, sheet_name=\"Total Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "organize_images(base_directory, total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_directories = get_strain_directories(base_directory=base_directory)\n",
    "gray_strain_directories = [join(s_dir,\"gray\") for s_dir in strain_directories]\n",
    "output_strain_directories = [join(s_dir, \"output\") for s_dir in gray_strain_directories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(strain_directories, gray_strain_directories, output_strain_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = get_strain_images_as_df(output_strain_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_excel(bacteria_workbook, 'Images', output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = pd.read_excel(bacteria_workbook, dtype=object, sheet_name=\"Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.set_index(\"strain\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data.set_index(\"strain\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dataset = merge_datasets(images_data, total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_excel(bacteria_workbook, 'CNN Dataset', cnn_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
